{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "055c54e2-ee9a-4542-85c7-a2ff17812efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../wizard_oz.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af6757e6-3ff2-4e4d-a99d-eb5b3c292025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters : 232333\n"
     ]
    }
   ],
   "source": [
    "print(f'length of dataset in characters : {len(text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f292a790-f9e5-4231-b42d-d056c954aa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿\n",
      "\n",
      "  DOROTHY AND THE WIZARD IN OZ\n",
      "\n",
      "  BY\n",
      "\n",
      "  L. FRANK BAUM\n",
      "\n",
      "  AUTHOR OF THE WIZARD OF OZ, THE LAND OF OZ, OZMA OF OZ, ETC.\n",
      "\n",
      "  ILLUSTRATED BY JOHN R. NEILL\n",
      "\n",
      "  BOOKS OF WONDER WILLIAM MORROW & CO., INC. NEW YORK\n",
      "\n",
      "\n",
      "  [Illustration]\n",
      "\n",
      "\n",
      "  COPYRIGHT 1908 BY L. FRANK BAUM\n",
      "\n",
      "  ALL RIGHTS RESERVED\n",
      "\n",
      "\n",
      "         *       *       *       *       *\n",
      "\n",
      "\n",
      "  [Illustration]\n",
      "\n",
      "\n",
      "  DEDICATED TO HARRIET A. B. NEAL.\n",
      "\n",
      "\n",
      "         *       *       *       *       *\n",
      "\n",
      "\n",
      "To My Readers\n",
      "\n",
      "\n",
      "It's no use; no use at all. The children won't let me stop telling tales\n",
      "of the Land of Oz. I know lots of other stories, and I hope to tell\n",
      "them, some time or another; but just now my loving tyrants won't allow\n",
      "me. They cry: \"Oz--Oz! more about Oz, Mr. Baum!\" and what can I do but\n",
      "obey their commands?\n",
      "\n",
      "This is Our Book--mine and the children's. For they have flooded me with\n",
      "thousands of suggestions in regard to it, and I have honestly tried to\n",
      "adopt as many of these suggestions as could be fitted into one story.\n",
      "\n",
      "After the wonderful success of\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd835abb-7d6e-4032-937b-0ddcdd056a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"&'()*,-.0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz﻿\n",
      "vocab_size = 81\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(f'{vocab_size = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ee683ee-6559-483e-a845-1a1f382f4d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)} \n",
    "\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join(itos[c] for c in l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59bf5c09-0b03-429e-a75a-8866f4866e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 62, 1, 73, 61, 58, 71, 58, 9]\n",
      "Hi there,\n"
     ]
    }
   ],
   "source": [
    "# example \n",
    "encoded = encode('Hi there,')\n",
    "decoded = decode(encoded)\n",
    "print(encoded)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4c985f5-fef0-49a7-8a00-5c4746227388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([232333]) torch.int64\n",
      "tensor([80,  0,  0,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44,\n",
      "        32, 29,  1, 47, 33, 50, 25, 42, 28,  1, 33, 38,  1, 39, 50,  0,  0,  1,\n",
      "         1, 26, 49,  0,  0,  1,  1, 36, 11,  1, 30, 42, 25, 38, 35,  1, 26, 25,\n",
      "        45, 37,  0,  0,  1,  1, 25, 45, 44, 32, 39, 42,  1, 39, 30,  1, 44, 32,\n",
      "        29,  1, 47, 33, 50, 25, 42, 28,  1, 39, 30,  1, 39, 50,  9,  1, 44, 32,\n",
      "        29,  1, 36, 25, 38, 28,  1, 39, 30,  1])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6575a9bc-70af-4a13-9920-0ec53e70e796",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*data.shape[0])\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a0b9ce-7a07-4035-8e67-65cc65ab1662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6577444-ecab-4439-95e9-d1ee3ef258a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: torch.Size([4, 8])\n",
      "tensor([[ 3,  0,  0,  3, 49, 58, 72,  9],\n",
      "        [68, 68, 72,  9,  3,  0, 54, 57],\n",
      "        [73, 58, 66, 72,  1, 72, 67, 54],\n",
      "        [78,  1, 54, 67, 57,  0, 72, 56]])\n",
      "outputs torch.Size([4, 8])\n",
      "tensor([[ 0,  0,  3, 49, 58, 72,  9,  1],\n",
      "        [68, 72,  9,  3,  0, 54, 57, 57],\n",
      "        [58, 66, 72,  1, 72, 67, 54, 69],\n",
      "        [ 1, 54, 67, 57,  0, 72, 56, 71]])\n",
      "------\n",
      "When input is [3] the target: 0\n",
      "When input is [3, 0] the target: 0\n",
      "When input is [3, 0, 0] the target: 3\n",
      "When input is [3, 0, 0, 3] the target: 49\n",
      "When input is [3, 0, 0, 3, 49] the target: 58\n",
      "When input is [3, 0, 0, 3, 49, 58] the target: 72\n",
      "When input is [3, 0, 0, 3, 49, 58, 72] the target: 9\n",
      "When input is [3, 0, 0, 3, 49, 58, 72, 9] the target: 1\n",
      "When input is [68] the target: 68\n",
      "When input is [68, 68] the target: 72\n",
      "When input is [68, 68, 72] the target: 9\n",
      "When input is [68, 68, 72, 9] the target: 3\n",
      "When input is [68, 68, 72, 9, 3] the target: 0\n",
      "When input is [68, 68, 72, 9, 3, 0] the target: 54\n",
      "When input is [68, 68, 72, 9, 3, 0, 54] the target: 57\n",
      "When input is [68, 68, 72, 9, 3, 0, 54, 57] the target: 57\n",
      "When input is [73] the target: 58\n",
      "When input is [73, 58] the target: 66\n",
      "When input is [73, 58, 66] the target: 72\n",
      "When input is [73, 58, 66, 72] the target: 1\n",
      "When input is [73, 58, 66, 72, 1] the target: 72\n",
      "When input is [73, 58, 66, 72, 1, 72] the target: 67\n",
      "When input is [73, 58, 66, 72, 1, 72, 67] the target: 54\n",
      "When input is [73, 58, 66, 72, 1, 72, 67, 54] the target: 69\n",
      "When input is [78] the target: 1\n",
      "When input is [78, 1] the target: 54\n",
      "When input is [78, 1, 54] the target: 67\n",
      "When input is [78, 1, 54, 67] the target: 57\n",
      "When input is [78, 1, 54, 67, 57] the target: 0\n",
      "When input is [78, 1, 54, 67, 57, 0] the target: 72\n",
      "When input is [78, 1, 54, 67, 57, 0, 72] the target: 56\n",
      "When input is [78, 1, 54, 67, 57, 0, 72, 56] the target: 71\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(220)\n",
    "batch_size = 4 \n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size, ))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "\n",
    "    return x, y \n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:', xb.shape)\n",
    "print(xb)\n",
    "print('outputs', yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('------')\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f'When input is {context.tolist()} the target: {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3241ad7-64ec-4953-9899-4674c5763809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 81])\n",
      "tensor(4.9702, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "-2QlzX. za eUJ_DCu6wZ4L2g*iOkkw(R﻿)TOh﻿?a]Px1wM)4-\n"
     ]
    }
   ],
   "source": [
    "# implementing Bigram Language model (pytorch)\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(220)\n",
    "\n",
    "class BigramLngModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context \n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions \n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time stampe\n",
    "            logits = logits [:, -1, :]\n",
    "            # apply softmax to get probabilities \n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # sample from the distribution \n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLngModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_tokens=50)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "006f475d-0429-45df-9a31-2cf10e3fdc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d89fabc1-f1e6-4f61-8cc6-b91575982276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4253833293914795\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32 \n",
    "for steps in range(10000):\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step() \n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cc32364-a76c-447a-a975-1be68a239e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"Ithedst Soofis wilanegort dit urchithoulep!\" Wiloub,  weshe s r,\n",
      "\n",
      "nglamulof ouindin'ly tr coutopennd taverene otaurackend o s\n",
      "\"OThil ifuleme e ththe s h l\n",
      "ID rerls, athain beng, d, Thauso wixthy aly  s Olet biartheaimat ghathemathin'tathth cime thas arens VI ben, whe ouciocrtho I\n",
      "w as I Jand f Hork e'm t Ohabrit t Ze d\n",
      "bure\n",
      "\"Ozmeveed grory thengy a!\"Ilke Iteeyould us anthre oedl, 2z, d *ARende \"ard iveoupooosen\n",
      "\" btold  hean'vematy\n",
      "clvemirapte s abesthe, hey pe thy sedreime ve upino, THEYen pad\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c3250a6-7ce5-47ca-9e05-1fc7992fac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = torch.randint(len(data) - block_size, (batch_size, ))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f777402-7d1a-4ff4-a403-d1ca42bc18ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07f62395-88fb-49e0-acf1-cbd4cd50f24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn((8,))\n",
    "b = torch.randn((8,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96a20d43-3087-4f02-83cd-021e6f341fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8]), torch.Size([8]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55458e87-2598-433f-9824-1a23f54b2cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.stack([a,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0eaa92a6-52fd-46c1-96a3-94d096efcf37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ef1f08e-26c6-4018-a2a4-8f06d06d750c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2801,  1.4928, -0.9659, -0.1079, -0.5750,  0.1247,  0.8580,  0.0671],\n",
       "        [ 1.2205, -0.1888,  0.9430,  0.9115, -1.3430, -0.0974, -0.5551, -3.1363]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b9bb216a-eeb6-4d7a-8246-6a3ea15169a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# self attention \n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 32 \n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# single head self attention \n",
    "head_size = 16 \n",
    "key = nn.Linear(C,  head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "k = key(x) # (B,T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "\n",
    "wei = q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T) \n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "v = value(x)\n",
    "out = wei @ v \n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dd8ef306-9bef-483d-ad09-e43142ad1603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ad5689-a28e-4933-985d-4b21bc0fdc10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
